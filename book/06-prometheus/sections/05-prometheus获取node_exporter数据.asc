=== Prometheus获取node_exporter数据

添加上上步<<NODE_EXPORTER,node_exporter>>生成的node_exporter.crt到prometheus所在目录

* 在prometheus主机上操作

.为被添加的node设置域名解析
[source, bash]
----
cat <<EOF >>/etc/hosts
xxx.xxx.xxx.xxx node_exporter1
EOF
----

[IMPORTANT]
必须在prometheus所在主机上设置域名解析，否则会无法获取node_exporter信息

.复制node_exporter.crt到prometheus主机
[source, bash]
----
scp root@node_exporter1:~/prometheus-tls/node_exporter.crt /opt/prometheus-2.49.1.linux-amd64
----

添加以下配置信息到/opt/prometheus-2.49.1.linux-amd64/prometheus.yml

.prometheus.yml
[source, bash]
----
cat <<EOF> /opt/prometheus-2.49.1.linux-amd64/prometheus.yml
global:
  scrape_interval:     15s # By default, scrape targets every 15 seconds.

  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    monitor: 'codelab-monitor'

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label 'job=<job_name>' to any timeseries scraped from this config.
  - job_name: 'prometheus'

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'node_exporter'
    scheme: https
    tls_config:
      ca_file: node_exporter1.crt
    static_configs:
    - targets: ['node_exporter1:9100']

EOF
----

[IMPORTANT]
`- targets: ['node_exporter1:9100']` 这里必须使用前面配置好的域名 `node_exporter1`，不能用ip


.重载prometheus配置文件
[source, bash]
----
sudo systemctl reload prometheus.service
----

访问 http://部署prometheus的主机Ip:9090/
Status->Targets

.显示如图
image::prometheus_01.png[]